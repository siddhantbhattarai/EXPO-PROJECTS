{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHqT_kXVPq_u"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, LSTM, TimeDistributed\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QI3-yYjPvJB",
        "outputId": "94796382-14be-4f04-9893-fe282555defd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "file_path = '/content/drive/MyDrive/fer2013.csv'\n",
        "data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "Du3c95EWPzCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the emotion classes\n",
        "CLASS_LABELS = ['Anger', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sadness', 'Surprise']"
      ],
      "metadata": {
        "id": "9BY1E7BlP-_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "def preprocess_data(data):\n",
        "    images = np.array([np.fromstring(pixels, sep=' ').reshape(48, 48, 1) for pixels in data['pixels']])\n",
        "    images = images / 255.0  # Normalize\n",
        "    labels = to_categorical(data['emotion'], num_classes=len(CLASS_LABELS))\n",
        "    return images, labels"
      ],
      "metadata": {
        "id": "nNvTy5sPQD29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset\n",
        "images, labels = preprocess_data(data)\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "MQuCiYm_QGME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN model\n",
        "def build_cnn():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(len(CLASS_LABELS), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "IGxLo5aiQIo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN-LSTM model\n",
        "def build_cnn_lstm():\n",
        "    model = Sequential([\n",
        "        TimeDistributed(Conv2D(32, (3, 3), activation='relu'), input_shape=(1, 48, 48, 1)),\n",
        "        TimeDistributed(MaxPooling2D((2, 2))),\n",
        "        TimeDistributed(Conv2D(64, (3, 3), activation='relu')),\n",
        "        TimeDistributed(MaxPooling2D((2, 2))),\n",
        "        TimeDistributed(Flatten()),\n",
        "        LSTM(64, return_sequences=False),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(len(CLASS_LABELS), activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "-WDV-HmnQLco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train models\n",
        "cnn_model = build_cnn()\n",
        "cnn_model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwznnEiFQOWD",
        "outputId": "76bd970b-9e88-432e-c6c9-85c4cc0b9c7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 220ms/step - accuracy: 0.2741 - loss: 1.7882 - val_accuracy: 0.3985 - val_loss: 1.5660\n",
            "Epoch 2/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 199ms/step - accuracy: 0.4062 - loss: 1.5481 - val_accuracy: 0.4559 - val_loss: 1.4328\n",
            "Epoch 3/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 196ms/step - accuracy: 0.4436 - loss: 1.4507 - val_accuracy: 0.4700 - val_loss: 1.3792\n",
            "Epoch 4/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 197ms/step - accuracy: 0.4710 - loss: 1.3810 - val_accuracy: 0.4860 - val_loss: 1.3359\n",
            "Epoch 5/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 201ms/step - accuracy: 0.4931 - loss: 1.3336 - val_accuracy: 0.4984 - val_loss: 1.3164\n",
            "Epoch 6/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 191ms/step - accuracy: 0.5122 - loss: 1.2870 - val_accuracy: 0.5153 - val_loss: 1.2768\n",
            "Epoch 7/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 195ms/step - accuracy: 0.5354 - loss: 1.2182 - val_accuracy: 0.5181 - val_loss: 1.2648\n",
            "Epoch 8/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 192ms/step - accuracy: 0.5549 - loss: 1.1748 - val_accuracy: 0.5255 - val_loss: 1.2541\n",
            "Epoch 9/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 195ms/step - accuracy: 0.5686 - loss: 1.1272 - val_accuracy: 0.5233 - val_loss: 1.2634\n",
            "Epoch 10/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 196ms/step - accuracy: 0.5789 - loss: 1.1037 - val_accuracy: 0.5348 - val_loss: 1.2559\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b5490c894e0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_lstm_model = build_cnn_lstm()\n",
        "x_train_lstm = x_train.reshape(-1, 1, 48, 48, 1)\n",
        "x_val_lstm = x_val.reshape(-1, 1, 48, 48, 1)\n",
        "cnn_lstm_model.fit(x_train_lstm, y_train, validation_data=(x_val_lstm, y_val), epochs=10, batch_size=64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRcmda6jQQwp",
        "outputId": "3fa287fe-4cce-450b-93b9-791c686dcdec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 248ms/step - accuracy: 0.2602 - loss: 1.7966 - val_accuracy: 0.3907 - val_loss: 1.5624\n",
            "Epoch 2/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 238ms/step - accuracy: 0.4178 - loss: 1.5107 - val_accuracy: 0.4616 - val_loss: 1.3932\n",
            "Epoch 3/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 222ms/step - accuracy: 0.4854 - loss: 1.3512 - val_accuracy: 0.4804 - val_loss: 1.3504\n",
            "Epoch 4/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 224ms/step - accuracy: 0.5341 - loss: 1.2277 - val_accuracy: 0.5086 - val_loss: 1.2901\n",
            "Epoch 5/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 224ms/step - accuracy: 0.5814 - loss: 1.1131 - val_accuracy: 0.5179 - val_loss: 1.2792\n",
            "Epoch 6/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 230ms/step - accuracy: 0.6457 - loss: 0.9681 - val_accuracy: 0.5259 - val_loss: 1.2908\n",
            "Epoch 7/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 223ms/step - accuracy: 0.6989 - loss: 0.8272 - val_accuracy: 0.5235 - val_loss: 1.3814\n",
            "Epoch 8/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 222ms/step - accuracy: 0.7744 - loss: 0.6384 - val_accuracy: 0.5252 - val_loss: 1.5397\n",
            "Epoch 9/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 224ms/step - accuracy: 0.8399 - loss: 0.4680 - val_accuracy: 0.5107 - val_loss: 1.7657\n",
            "Epoch 10/10\n",
            "\u001b[1m393/393\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 228ms/step - accuracy: 0.8902 - loss: 0.3359 - val_accuracy: 0.5189 - val_loss: 1.9185\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b5491bf1480>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models\n",
        "cnn_accuracy = cnn_model.evaluate(x_test, y_test, verbose=0)[1]\n",
        "cnn_lstm_accuracy = cnn_lstm_model.evaluate(x_test.reshape(-1, 1, 48, 48, 1), y_test, verbose=0)[1]\n",
        "print(f\"CNN Accuracy: {cnn_accuracy}, CNN-LSTM Accuracy: {cnn_lstm_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNbPkDRKQUNH",
        "outputId": "591fbd32-0e46-49c8-f91e-eda333a7cbc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Accuracy: 0.5362184047698975, CNN-LSTM Accuracy: 0.5356612205505371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "best_model = cnn_model if cnn_accuracy > cnn_lstm_accuracy else cnn_lstm_model\n",
        "best_model.save('/content/drive/MyDrive/best_facial_expression_model.keras')\n"
      ],
      "metadata": {
        "id": "jsKT4d8WQWvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Real-time face detection and expression recognition\n",
        "def real_time_prediction():\n",
        "    model = tf.keras.models.load_model('/content/drive/MyDrive/best_facial_expression_model.keras')\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=5)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            face = gray_frame[y:y+h, x:x+w]\n",
        "            face = cv2.resize(face, (48, 48)).reshape(1, 48, 48, 1) / 255.0\n",
        "            prediction = model.predict(face)\n",
        "            emotion = CLASS_LABELS[np.argmax(prediction)]\n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
        "            cv2.putText(frame, emotion, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
        "\n",
        "        cv2.imshow('Facial Expression Recognition', frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "real_time_prediction()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32BrrUkdQeOG",
        "outputId": "809fb411-adaa-4fdd-d825-7de2d384fc1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 10 variables whereas the saved optimizer has 18 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/best_facial_expression_model.keras /content/"
      ],
      "metadata": {
        "id": "JMpWBR5ZdU1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/best_facial_expression_model.keras')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "ghiq3_JBfHU_",
        "outputId": "60d944bf-8be8-49e2-cdc9-96924257f4c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_28e2e822-69b4-496a-b8f3-d88baa7ea434\", \"best_facial_expression_model.keras\", 10102733)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wH9glXUIfJvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}